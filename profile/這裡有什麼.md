# 這裡有什麼？

目前我已經完成了幾個項目，包括：

1. [**DocsaidKit**](https://github.com/DocsaidLab/DocsaidKit)：裡面有一些我平常在用的一些小工具，是個工具箱的角色。
2. [**DocAligner**](https://github.com/DocsaidLab/DocAligner)：這是一個提供文本定位功能的專案，主要用來定位文件的四個角點。
3. [**DocClassifier**](https://github.com/DocsaidLab/DocClassifier)：這是一個用於提供文本相似度計算的專案，發想於我的朋友，他先完成了前期的程式開發和可行性驗證，接著把這個想法交給我，讓我完成了後續細節之後，發布在這裡。
4. [**GmailSummary**](https://github.com/DocsaidLab/GmailSummary)：這是一個用於提供 Gmail 郵件摘要的專案，串接了 Gmail API 和 OpenAI API，完成大量郵件的摘要功能，並且每天固定時間推送更新資訊。

還有一些其他項目還在規劃中：

5. **DocsaidOCR**：

    說到 OCR 就一定得提到業界的領頭羊：[**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR)。他們的模型效果很好，功能涵蓋也非常全面。通常不管是遇到什麼問題，就先過去他們家逛逛，可能就會找到解決方法。但是他們常有繁體中文無法正確辨識的問題，另外他們採用了 PaddlePaddle 框架，讓我這個 PyTorch 使用者感到諸多不方便。

    因此，我在過去幾年前，遵循著他們的指引，從頭打造一套用於繁體中文的商業文件 OCR 解決方案，對比其他在臺灣的廠商，非常具有競爭力。只是這套系統被買斷了，我不能再用它。事隔多年，我對於同樣的問題有了新的思考，所以我打算重新規劃模組架構和使用全新的演算法再來一次。

    其中內容可能包含但不限於以下議題：

      - **TextDetector:** 該如何設計一個可以判別多方向文字的模組？速度和精度能不能兼得？
      - **TextRecognizer:** 原本模型僅涵蓋中日韓表意文字共 3 萬字，能不能擴充到 10 萬字？資料該去哪裡找？
      - **DocVQA:** 面對一份結構複雜的文件，我們該如何設計一個可以回答問題的模組？這個模組的設計應該要有多少的可擴充性？之前嘗試過 ChatGPT 和 PaddleOCR，但效果不太好，該如何改進？
      - **DocGenerator:** 合成文本已經有非常多的公開資料集，但是該如何設計一個高效率的商業文件合成模組？
      - **HandWritting:** 手寫文字辨識是一個非常有趣的議題，最有名的就是 mnist 資料集，但是這個資料集太過簡單，我們該思考的是如何應對中文手寫文字的挑戰？
      - **TableAnalysis:** 表格解析在過去幾年來一直是一個非常困難的議題，我有過一些嘗試，包含使用 AWS 和 Google 的解決方案，但他們對於無框線及不規則表格的解析能力都不夠，該如何改進？

話說回來，我覺得做 OCR 是個 CP 值相對低的工作。因為你要解決的問題不僅需要涵蓋到多個分支領域，工作量大。反觀在商業上的 OCR 產品琳瑯滿目，很難做出差異化，使用者也不會在意那些長尾數據，通常不會為此而多付錢。

總之這就是一件非常需要熱情來支撐的事情。對我來說，未知就是一個很大的動力，所以我會持續推進它。

此外，還有一些其他的想法，但細節還沒有很成熟，所以請原諒我先暫時不公開。

未來所有我所掌握的知識或是有趣的題目，都會在這裡分享。

附帶一提，我還有一個記錄日常開發的專案：[**blog**](https://github.com/DocsaidLab/blog)，這個項目是基於 Facebook 開源的 docusaurus 的專案，很多東西我都還沒搞清楚，畢竟前端框架我平常沒什麼接觸。所以網站上沒有炫目華麗的功能，就僅是一些文章而已，我把部落格的內容放在 [**docsaid.org**](https://docsaid.org) 內。

## 設計理念

在我的觀念中，一個項目的完整性不僅僅是它的功能，還有它的文檔、測試、CI/CD、版本控制等等。

同時，我也必須承認自己的健忘，所以我會盡量把我所做的事情都記錄下來。

基於我的理念，打造一個深度學習專案的基本架構應該要涵蓋幾個內容：

  - 模型怎麼做？
  - 做得好不好？
  - 模型怎麼用？

這樣的架構可以讓我們更好的去理解和討論一個項目，也可以讓我們更好地去使用和開發它。

舉例來說，為了可以復現一個實驗結果，我們必須考慮到工作環境的問題，這樣才能確保我們之間的討論可以在同一個基礎上進行。所以我引入的 Docker 訓練模組來作為解決方案。

如果你平常不用容器技術，那你看到我提供的訓練程式碼，可能會因此而感到困惑：

<div align="center">

**這什麼鬼？事情從糟糕變得難以理解？**

</div>


但是根據我在這個領域從（踩）業（坑）的經驗，你會發現 C++ 是個坑、CUDA 是個坑、ONNX 是個坑、Python 和 PyTorch 也是個坑，更別說這些坑都要建置 Linux, Windows, MacOS 上。你不學會 Docker，你就會發現你的生活就是一個坑。~~（有沒有一種可能是 Docker 也是一個坑？）~~

另外一個例子，就是對於我們訓練模型的架構抽象。我們可以用一個簡單的 `YAML` 文件來描述我們的模型，這樣我們就可以把模型的架構和訓練的參數分開，這樣我們就可以更好的去管理我們的模型。我們可以將模型大概分為幾個結構，分別是 Backbone, Neck, Head, Loss, Metric。透過這樣的抽象，我們可以更好的去理解我們的模型，也可以更好的去訓練我們的模型。

最後一個例子是關於訓練完成模型之後的事情。

我們在訓練模型的過程中，可能會採用很多損失函數，很多優化器和模型分支等，但在推論階段卻是截然不同的方式。最簡單的例子就是：你不可能直接把訓練的 ckpt 檔用在產品環境吧！（還是其實有？）再怎麼說，也得用個推論框架包裝一下，例如 ONNX 或是 TorchScript 之類的。

因此，我們除了完成模型訓練之外，還會提供一個簡單的推論模型，這樣可以方便你更好地去使用我們提供的模型功能。

＊

雖然我是中文母語使用人士，但在目前我提供的項目中，還是會優先採用英文的說明文件，畢竟這個行業的主要領航者都是講英文的。但說真的，我也不是特別擅長撰寫說明文件，所以如果你看到我提供的文件有什麼問題，歡迎你提出來，我會很樂意去改進它。

如果你想看中文的，我有把同樣的內容放在一起，從 README 的最左上角點選「中文」就可以看到了。
